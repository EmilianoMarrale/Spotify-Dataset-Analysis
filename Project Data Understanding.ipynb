{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Datamining Project - Spotify Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9381bbd755c5686"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data understanding and preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6731cc06"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66e246d964a3cfd5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Import and simple data visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ccb8686"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', skipinitialspace=True)\n",
    "\n",
    "df_test = pd.read_csv('test.csv', skipinitialspace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "08281784"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24953ca4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aa056ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b9a2c23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a667d03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca098da9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab8f6cea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mean = df_train.drop(columns=['name', 'explicit', 'artists','mode','popularity_confidence', 'album_name', 'features_duration_ms'], axis=1)\n",
    "df_mean.groupby(['genre']).mean().T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f70d4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking for duplicated records"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbc7fb445a655be4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e27631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicated records\n",
    "\n",
    "print(df_train.duplicated().sum(), df_test.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicated songs\n",
    "print(df_train['name'].duplicated().sum(), df_test['name'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25067410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking differences between duration_ms and features_duration_ms, also there we can notice that most records differ by 1\n",
    "\n",
    "values = df_train[df_train['duration_ms'] != df_train['features_duration_ms']]\n",
    "columns_to_print = ['duration_ms', 'features_duration_ms']\n",
    "values[columns_to_print]\n",
    "\n",
    "valu = values['features_duration_ms'] - values['duration_ms']\n",
    "\n",
    "print(\"Number of different records: \", valu.size)\n",
    "\n",
    "differences_count = 0\n",
    "for i in valu:\n",
    "    if(i != 1 and i != -1):\n",
    "        differences_count += 1\n",
    "        \n",
    "print(\"Number of different records with a difference greater than 1: \", differences_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024cb0f",
   "metadata": {},
   "source": [
    "### Checking for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a84624",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in list(df_train.columns):\n",
    "    containsNaN = df_train[column].isnull().sum()\n",
    "    if(containsNaN):\n",
    "        print(\"Column: \" + column + \" hasNaN: \" + str(containsNaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in list(df_test.columns):\n",
    "    containsNaN = df_test[column].isnull().sum()\n",
    "    if(containsNaN):\n",
    "        print(\"Column: \" + column + \" hasNaN: \" + str(containsNaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['popularity_confidence'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data distribution\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "352d33592a33bf06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.groupby('genre')['popularity'].mean().sort_values().plot(kind='bar')\n",
    "plt.ylabel('popularity')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e82f39d09848db23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train['genre'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf23d1839b0a891"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting the distribution of the features\n",
    "\n",
    "fig = plt.figure (figsize = (10,10))\n",
    "fig_dims = (4,4)\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0,0))\n",
    "df_train['explicit'].value_counts().plot(kind='bar', title='Explicit and not explicit songs')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0,1))\n",
    "df_train['mode'].value_counts().plot(kind='bar', title='Major and minor songs')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (1,0))\n",
    "df_train['acousticness'].hist()\n",
    "plt.title('Acousticness')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (1,1))\n",
    "df_train['danceability'].hist()\n",
    "plt.title('Danceability')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (2,0))\n",
    "df_train['energy'].hist()\n",
    "plt.title('Energy')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (2,1))\n",
    "df_train['instrumentalness'].hist()\n",
    "plt.title('Instrumentalness')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0,2))\n",
    "df_train['liveness'].hist()\n",
    "plt.title('Liveness')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (1,2))\n",
    "df_train['loudness'].hist()\n",
    "plt.title('Loudness')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (2,2))\n",
    "df_train['speechiness'].hist()\n",
    "plt.title('Speechiness')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0,3))\n",
    "df_train['tempo'].hist()\n",
    "plt.title('Tempo')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (1,3))\n",
    "df_train['valence'].hist()\n",
    "plt.title('Valence')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (2,3))\n",
    "df_train['popularity'].hist()\n",
    "plt.title('Popularity')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (3,0))\n",
    "df_train['key'].hist()\n",
    "plt.title('Key')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (3,1))\n",
    "df_train['time_signature'].hist()\n",
    "plt.title('Time signature')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (3,2))\n",
    "df_train['popularity_confidence'].hist()\n",
    "plt.title('Popularity confidence')\n",
    "\n",
    "plt.subplot2grid(fig_dims, (3,3))\n",
    "df_train['duration_ms'].hist()\n",
    "plt.title('Duration_ms histogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "646dc792539a5283"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting the distribution of the n_beats feature\n",
    "plt.hist(df_train['n_beats'], bins=[0, 200, 400, 600, 800, 1000, 1300, max(df_train['n_beats'])], edgecolor='black')\n",
    "plt.title('Number of beats')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abf555f63d5f5128"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting the distribution of the n_bars feature\n",
    "plt.hist(df_train['n_bars'], bins=[0,50, 100,150, 200, 250,300,400, max(df_train['n_bars'])], edgecolor='black')\n",
    "plt.title('Number of bars')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436b8ae2ca638ec1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Normal distribution of numerical values\n",
    "from scipy.stats import norm\n",
    "\n",
    "for attribute in list(df_train.columns):\n",
    "    if(df_train[attribute].dtype == np.float64 or df_train[attribute].dtype == np.int64):\n",
    "        x = np.linspace(df_train[attribute].min(), df_train[attribute].max(), 1000)\n",
    "\n",
    "        mu = df_train[attribute].mean()\n",
    "        sigma = df_train[attribute].std()\n",
    "\n",
    "        # Calculate the PDF\n",
    "        pdf = norm.pdf(x, loc=mu, scale=sigma)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(x, pdf, 'r', label='PDF')\n",
    "        plt.xlabel(attribute)\n",
    "        plt.ylabel('PDF Value')\n",
    "        plt.title('Normal Distribution of ' + attribute)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef561000b1a89d57"
  },
  {
   "cell_type": "markdown",
   "id": "518bd84b",
   "metadata": {},
   "source": [
    "### Genre splitting and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d942459",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_train['genre'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "genresData = []\n",
    "for genre in df_train['genre'].unique():\n",
    "    genresData.append(df_train[df_train['genre'] == genre])\n",
    "    \n",
    "genresData[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7681af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Initialize empty lists to store information\n",
    "genre_list = []\n",
    "feature_1_list = []\n",
    "feature_2_list = []\n",
    "correlation_list = []\n",
    "\n",
    "for genre_df in genresData:\n",
    "    # Drop NaN values and unwanted columns\n",
    "    genre_df = genre_df.dropna(axis=1)\n",
    "    genre_df = genre_df.drop(columns=['name', 'explicit', 'artists', 'album_name', 'features_duration_ms'], axis=1)\n",
    "    genre = genre_df.iloc[0]['genre']\n",
    "    \n",
    "    for feature_1 in list(genre_df.columns):\n",
    "        if feature_1 != 'genre':\n",
    "            for feature_2 in list(genre_df.columns):\n",
    "                if feature_2 != 'genre' and feature_1 != feature_2:\n",
    "                    corr, p_val = pearsonr(genre_df[feature_1], genre_df[feature_2])\n",
    "                    if abs(corr) > 0.7:  # Filter based on correlation threshold\n",
    "                        if not feature_1 in feature_2_list or not feature_2 in feature_1_list:\n",
    "                            genre_list.append(genre)\n",
    "                            feature_1_list.append(feature_1)\n",
    "                            feature_2_list.append(feature_2)\n",
    "                            correlation_list.append(corr)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "correlation_df = pd.DataFrame({\n",
    "    'genre': genre_list,\n",
    "    'feature_1': feature_1_list,\n",
    "    'feature_2': feature_2_list,\n",
    "    'correlation': correlation_list\n",
    "})\n",
    "\n",
    "correlation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b223101",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(set(feature_1_list)) + list(set(feature_2_list))\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbe048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_scatter_matrix = df_train.drop(columns=['name', 'artists', 'genre', 'explicit','album_name'])\n",
    "\n",
    "    \n",
    "    \n",
    "pd.plotting.scatter_matrix(df_scatter_matrix[list(set(features_list))], figsize=(16, 8))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data correlation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a1c0fadd64bae3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568186f0efa078e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Scatter plot of 'duration_ms' and 'feature_duration_ms'\n",
    "plt.scatter(df_train['duration_ms'], df_train['features_duration_ms'])\n",
    "plt.xlabel('duration_ms')\n",
    "plt.ylabel('feature_duration_ms')\n",
    "plt.title('Scatter plot of duration_ms and feature_duration_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3475cb0c6dd431",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pearson correlation heatmap\n",
    "import seaborn as sns\n",
    "df_mean = df_train.drop(columns=['name', 'explicit', 'artists','mode','popularity_confidence', 'album_name', 'genre'], axis=1)\n",
    "\n",
    "# Compute the correlation matrix and make it larger\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = df_mean.corr()\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1f33ca22c7e866bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
